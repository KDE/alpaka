<?xml version="1.0" encoding="UTF-8"?>

<!--
SPDX-FileCopyrightText: 2023 Loren Burkholder <computersemiexpert@outlook.com>

SPDX-License-Identifier: GPL-2.0-only OR GPL-3.0-only OR LicenseRef-KDE-Accepted-GPL
-->

<kcfg xmlns="http://www.kde.org/standards/kcfg/1.0"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
      xsi:schemaLocation="http://www.kde.org/standards/kcfg/1.0
                          http://www.kde.org/standards/kcfg/1.0/kcfg.xsd" >
  <include>KUser</include>
  <include>QEventLoop</include>
  <include>KLLMInterface.h</include>
  <include>KLLMConstants.h</include>
  <kcfgfile name="alpakarc"/>
  <group name="Ollama">
    <entry name="ServerUrl" type="Url">
      <label>The URL to the Ollama instance</label>
      <default code="true">KLLMCore::ollamaUrl()</default>
    </entry>
      <entry name="NumCtx" type="Int">
        <label>Context size</label>
        <default>2048</default>
      </entry>
      <entry name="RepeatLastN" type="Int">
        <label>How far back for the model to look back to prevent repetition</label>
        <default>64</default>
      </entry>
      <entry name="RepeatPenalty" type="Double">
        <label>Sets how strongly to penalize repetitions</label>
        <default>1.1</default>
      </entry>
      <entry name="Temperature" type="Double">
        <label>Increasing the temperature will make the model answer more creatively</label>
        <default>0.8</default>
      </entry>
      <entry name="Seed" type="Int">
        <label>Seed to use for generation</label>
        <default>-1</default>
      </entry>
      <entry name="NumPredict" type="Int">
        <label>Maximum number of tokens to predict when generating text</label>
        <default>-1</default>
      </entry>
      <entry name="TopK" type="Int">
        <label>Reduces the probability of generating nonsense</label>
        <default>40</default>
      </entry>
      <entry name="TopP" type="Double">
        <label>Reduces the probability of generating nonsense (works with top_k)</label>
        <default>0.9</default>
      </entry>
      <entry name="MinP" type="Double">
        <label>Alternative to the topp, and aims to ensure a balance of quality and variety</label>
        <default>0</default>
      </entry>
  </group>
  <group name="LLM">
    <entry name="SystemPrompt" type="String">
      <label>The system prompt for the LLM</label>
      <default code="true">
        [] {
            KUser user;
            return QStringLiteral("You are an AI assistant. You are speaking to a person named %1. "
                                  "Be helpful, professional, and courteous. Do not give inaccurate "
                                  "information.")
                .arg(user.property(KUser::UserProperty::FullName).toString());
        } ()
      </default>
    </entry>
    <entry name="Model" type="String">
      <label>The model used to generate responses</label>
    </entry>
    <entry name="ShowDebugInfo" type="bool">
      <label>Show debug information</label>
      <default>false</default>
    </entry>
  </group>
  <group name="General">
    <entry name="SystemTray" type="bool">
      <label>Close Alpaka to system tray</label>
      <default>false</default>
    </entry>
    <entry name="AutoScrollDown" type="bool">
      <label>Auto scroll down when a new prompt is posted</label>
      <default>true</default>
    </entry>
  </group>
</kcfg>
