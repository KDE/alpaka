# Kandalf

Kandalf is a client for Ollama built with Kirigami.

# Getting started

To run Kandalf, you will need to install [Ollama](https://ollama.ai) and have it serving on `http://localhost:11434`. You will also need to install a model for ollama to use; you can do so by running `ollama pull llama2`. After that, you can build and run Kandalf and it will interface with the Ollama API.
