<!--
SPDX-FileCopyrightText: 2023 Loren Burkholder <computersemiexpert@outlook.com>

SPDX-License-Identifier: CC0-1.0
-->

# Kandalf

Kandalf is a client for Ollama built with Kirigami.

# Getting started

To run Kandalf, you will need to install [Ollama](https://ollama.ai) and have it serving on `http://localhost:11434`. You will also need to install a model for ollama to use; you can do so by running `ollama pull llama2`. After that, you can build and run Kandalf and it will interface with the Ollama API.
